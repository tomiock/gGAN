\chapter{Plantejament de l'hipòtesi}

Podria haver anat per altres vies com la generació d'imatges amb color o l'implementació d'un d'una porta $X$ en una part específica del circuit quàntic que genera les imatges, que al posar-la o no, el model generes dos tipus d'imatge a través del mateix circuit. Tanmateix, les dues propostes requerien de desenvolupar nous conceptes, ja que són idees meves pròpies, però al no tindre el coneixements necessaris vaig descartar-les.

Llavors, al ser l'implementació de les funcions no-lineals un assumpte lleugerament conflictiu entre els diversos models de xarxes neuronals quàntiques, com ja he comentat en la secció \ref{qcircuits}, havia decidit des d'un principi centrar-me en aquesta qüestió en concret. 

La pregunta a investigar és la següent: \\
L'incorporació d'una funció no-lineal en el circuit quàntic del model, a partir d'una mesura parcial, causa que el model arribi més ràpidament al punt òptim?

En altres paraules, volia veure si la mesura parcial afectaria positivament en l'eficiència del model, fent que la generació de les imatges desitjades es dones a terme en un menor temps. 

Sembla una qüestió senzilla, però la dificultat del experiment radica en crear la xarxa neuronal en si, amb totes les seves parts accessibles per poder fer els canvis que siguin necessaris. L'única manera de fer l'experiment seria programant el model, una tasca que tenia clar que faria des de el principi.

\chapter{Programació del model}

Posteriorment a començar a programar el model, jo ja sabia que ho havia de realitzar en Python, ja havia creat algun algoritmes abans de començar aquest treball i tenia experiència construint i executant circuits quàntics amb Cirq \cite{cirq}, una eina desenvolupada per Google. A més a més, sabia de l'existència de TensorFlow Quantum \cite{tfq}, una altra eina desenvolupada per Google destinada a la creació de xarxes neuronals quàntiques i algoritmes de \textit{quantum mechine learning} en general. També tenia experiència en aquest \textit{framework}. Per tant, TensorFlow Quantum va ser la meva primera opció, tenia pensat basar el meu codi en el tutorial de TensorFlow sobre una xarxa convolucional generativa adverbial. Havia de canviar el generador per un circuit quàntic que s'optimitza a partir d'un diferenciador\footnote{Objecte que calcula el gradient d'un circuit quàntic.} automàtic provinent de TensorFlow Quantum. Els canvis que corresponien al discriminador simplement havien de ser un canvi d'arquitectura, passar d'una xarxa més complexa a una de més simple que només consistiria a en unes poques capes totalment connectades. 

El primer problema que em vaig trobar va ser la creació del \textit{dataset} que alimenta a la xarxa discriminativa. A causa de la peculiaritat de les imatges que volia generar, havia de crear-lo manualment. Usualment les imatges que componen els \textit{datasets} utilitzats en \textit{deep machine learning} són extretes de bancs d'informació amb mides enormes. En el meu cas, havien de ser generades per mi, per tant havia de convertir matrius de Numpy en \textit{datasets} de TensorFlow. Recordo que en va costar arribar a tindre la solució a aquest problema. 

\section{Discriminador}

Una vegada ja tenia fet el \textit{dataset} em vaig posar a fer el model. En el tutorial per una \href{https://www.tensorflow.org/tutorials/generative/dcgan}{DCGAN (GAN convolucional)} els dos models eren entrenats per la funció \code{train\_step()}, que representa una iteració en el procés d'optimització. En aquesta es crida a la funció \code{tf.GradientTape} per guardar el diferenciador automàtic. El problema que vaig dintre amb aquesta funció es que directament no funcionava amb el discriminador, aquest no era optimitzat. Després d'intentar solucionar l'error pels meus propis medis, mirant la causa d'aquest i de buscar a forums la solució o causa, em vaig rendir. Ja havia estat uns quants mesos intentant desenvolupant el model amb TensorFlow i TensorFlow Quantum. Havia creat les capes del generador quàntic manualment, també ho havia fet amb el optimitzador\footnote{No sabia ni si funcionarien adequadament, degut que per provar-ho, tenia que tenir tot el model enllestit.}. Tenia el model gairebé acabat, però al no poder optimitzar el discriminador em vaig veure obligat a canviar d'estrateiga. 

Existeixen dos grans \textit{frameworks} per crear i executar circuits quàntics: Cirq \cite{cirq}, desenvolupat per Google, i Qiskit \cite{qiskit}, creat per IBM. Una vegada vaig decidir no continuar amb Cirq, havia de provar amb Qiskit. La veritat, havia d'haber començar amb Qiskit des de el principi, és més útil (té moltes més característiques), i el més important, té una major comunitat, per tant, es més fàcil trobar solucions als error que pots tenir i és més fàcil trobar a persones disposades a ajudar-te.

Al igual que Cirq té un \textit{framework} per poder desenvolupar xarxes neuronals (TensorFlow Quantum); Qiskit també té el seu, anomenat PyTorch \cite{pytorch_2019}, no obstant no té una integració tan directa, ja que no estan desenvolupats pel mateix equip, ni la mateixa companyia. 

Per tant, al canviar de Cirq a Qiskit, també havia de canviar de TensorFlow a PyTorch, però no tenia res d'experiencia amb PyTorch, sabia que la transició seria complicada, i tenia raó. No vaig ni aconseguir crear el \textit{dataset} que contenia les imatges que alimentar al discriminador. 

Després d'intetar-lo amb TensorFlow Quantum i amb PyTorch, vaig decidir prescindir de \textit{frameworks} per crear models de \textit{machine learning}. El discriminador, al ser una xarxa tan simple, la podia crear des de zero. Llavors vaig començar a buscar codi, volia una xarxa neuronal que feta amb Numpy, una llibreria de Python per fer càlculs amb vectors i matrius amb la qual tenia bastant experiència. 

Després de provar dues opcions que més o menys m'agradaven\footnote{Buscava codi estructurat d'una forma en concret, que estigui dissenyat amb la filosofia de \textit{Object Oriented Programming}, una forma d'escriure codi en el qual tot s'implementa en un sol objecte.}, va aparèixer un repositori\footnote{\href{https://github.com/mnielsen/neural-networks-and-deep-learning}{link del respositori}} de Michael Nielsen, un dels autors de \textit{Quantum Computation and Quantum Information} \cite{QCandQI} que em va salvar. 

El repositori tenia codi per xarxes neuronals que estava estructurat d'una forma que m'agradaba i encara més important, que entenia. Inclús tènia diverses versions d'una mateixa xarxa neuronal, amb un nivell de complexitat diferent. Llavors, a partir del model més simple que havia en el repositori \footnote{Es pot veure el codi original al apèndix \ref{lst:disc_original}.}, vaig començar a desenvolupar el discriminador. 

Com es pot veure al codi final per el discriminador al apèndix \ref{lst:disc_final}, he fet bastants canvis, però no he canviat l'estructura o el funcionament teòric. La majoria dels canvis són per afegir més funcionalitat al model, com per exemple l'enmagatzematge de les dades per poder al final veure-les en un gràfic. 

El canvi més important és que inclou les dues formes d'optimitzar el model, amb dues funcions de pèrdua que funcionen de manera diferents però que són la mateixa, la \textit{Binary Cross Entropy} i la \textit{MinMax}. Ja he parlat d'aquestes dues funcions en la part teòrica del treball. Això en el codi està materialitzat en dues funcions\footnote{Funcions de Python.} diferents, \code{backprop\_bce()} i \code{backprop\_minimax()}. No fa falta entrar en detall sobre que va cadascuna de les funcions, degut a que, fan el mateix i no tenen ninguna diferencia en termes de eficàcia o rapidesa. Les vaig fer tan sols per comprovar que no hi hauria ninguna diferencia. El codi final del discriminadors es pot veure al apèndix \ref{lst:disc_final}. També en el repositori del treball hi ha un altre arxiu anomenat \code{discriminator.py}, que conté una altre versió en la qual intentava implementar diverses funcions d'activació en el model, però no ho vaig aconseguir, tanmateix, no em preocupa perquè no es una part vital del treball, no passa res per tindre el discriminador només amb la sigmoide. 

\section{Generador}

El desenvolupament de l'altre part del model, el generador, va ser molt diferent. Després de provar a fer-ho amb TensorFlow, sense obtindre bons resultats, no tenia altra opció que fer-ho tot manualment i jo mateix\footnote{No em vaig ni plantejar buscar codi per internet perquè pensava que els autors dels paper que vaig llegir, les úniques persones que sabia que podien tindre el codi, no el penjarien.}, no obstant, ja tenia experiència en fer pseudo-xarxes neuronals quàntiques i això em tranquil·litzava . Sabia perfectament el que tenia que fer, i com ho havia de fer: Implementar el mètode de \textit{parameter shift} en els circuits quàntics dels quals vaig parlar en la secció \ref{qcircuits}.

Una vegada vaig crear els circuits quàntics amb una funció fins a un punt en el qual sentia que ja estava tot perfecte, em vaig posar amb la optimització, de la qual parlaré a continuació. 

Primer de tot cal remarcar que el model s'optimitza a partir d'un \textit{batch}, es a dir, un grup d'imatges, en aquest cas, un grup de dades. S'agafa la mitjana dels errors de cada \textit{batch}, i s'actualizen els paràmetres a partir d'aquesta. La motivació per treball en  \textit{batch} i no dades individuals es perquè s'ha de mirar l'error d'unes quantes dades a la vegada, d'aquesta manera l'optimització és més robusta.

Tornant al funcionament del procediment, per començar s'han d'agafar els paràmetres a optimitzar, que estaran en forma d'un vector $\theta$, escollir un d'ells que anomenaré $\theta_{i}\,$, que és el paràmetre que s'optimitzarà, i crear un vector de pertubació $\Delta_{i}\,$. Aquest vector consisteix en un vector amb la mateixa mida que $\theta\,$, però amb tot de zeros, menys a la posició del paràmetre que es vol optimitzar, en la qual tindrà un $1$.

Llavors es creen dos vectors de paràmetres nous, $\theta^{+}_{i}$ i $\theta^{+}_{i}$, multiplicant $\pm\frac{\pi}{4}$ pel vector de pertubació, i sumant el resultat al vector de paràmetres original\footnote{Cada un d'aquests vectors de paràmetres té una petita variació en un paràmetre, i cada vector té una variació en un sentit.}. A continuació, es creen dues imatges, cadascuna corresponent a un dels vectors de paràmetres creats, una amb $\theta^{+}_{i}$ i l'altra amb $\theta^{-}_{i}\,$. Per últim, s'avalua la funció de pèrdua per a cada imatge generada i es treu la diferencia entre elles, d'aquesta manera calculant una derivada $\pdv{\mathcal{L}}{\theta_i}$respecte al paràmetre $\theta_{i}\,$. 
Una vegada es té una derivada per a cada paràmetre de $\theta$ es pot construir el vector gradient $\nabla_\theta$. He de dir aquest vector, ha de tenir la mateixa mida que el vector $\theta\,$, degut a que cada element en el gradient correspon a la derivada d'un paràmetre de $\theta$.

Al llarg de l'optimització es van sumant les derivades a $\nabla_\theta$, si això es fa per a tots els paràmetres de $\theta$ i per a totes les dades del \textit{batch}, finalment es pot treure la derivada mitjana dividint els elements de $\nabla_{\theta}$ per la quantitat de dades que hi han en un \textit{batch}.

Amb el gradient $\nabla_{\theta}$ resultat es poden finalment optimitzar tots els paràmetres, d'acord amb les derivades mitjanes de les quals està compost. 
 
 
\begin{figure}
	\HRule \\[-.5cm]
	\begin{algorithmic}
		\State{$\nabla = 0$} \Comment{Creació del vector  $\nabla$ que te la mateixa mida que $\theta$}
		\For{soroll en batch}
		\For{paràmetre $\theta_i$ en  $\theta$}
		\State{$\Delta_i = 0$} \Comment{Creació del vector pertubació d'acord amb el vector $\theta_i$}
		\State{$\theta^{+}_i = \theta + \frac{\pi}{4}\Delta_i$}
		\State{$\theta^{-}_i = \theta - \frac{\pi}{4}\Delta_i$}
		\\
		\State{Imatge\textsubscript{1} = generador(soroll, $\theta^+_i$) } 
		\State{Imatge\textsubscript{2} = generador(soroll, $\theta^-_i$) } \Comment{Generació de les imatges}
		\\
		\State{Predicció\textsubscript{1} = discriminador(Imatge\textsubscript{1})} 	\State{Predicció\textsubscript{2} = discriminador(Imatge\textsubscript{2})} \Comment{El discriminador posa una etiqueta a cada imatge}
		\\
		\State{Diferencia\textsubscript{$i$} = $\mathcal{L}$(Predicció\textsubscript{1}) - $\mathcal{L}$(Predicció\textsubscript{2})}
		\\
		\State{$\nabla_\theta = \nabla_i + $ Diferencia\textsubscript{$i$}} \Comment{On $\mathcal{L}$ és la funció de pèrdua del generador}
		\EndFor
		\EndFor
		\\
		\For{$\theta_i$ en $\theta$ i $\nabla_i$ en $\nabla_\theta$} \Comment{Per a cada paràmetre i per a cada error}
		\State{$\theta^{t+1}_i = \theta_i + \frac{\eta}{M}\nabla_i$} \Comment{Actualització del paràmetre amb la mitjana de l'error que correspon a aquest paràmetre}
		\EndFor
	\end{algorithmic}
	\HRule \\[-.4cm]
	\caption{\textbf{Pseudocodi per una xarxa generativa adversativa.} Em refereixo al input de la xarxa generacional com a soroll, ja que és més encertat d'aquesta manera. El vector $\nabla$ té la mateixa mida que el vector de paràmetres $\theta$, cal notar que també té la mateixa mida els vectors $\theta^\pm_i$, degut a que aquests vectors són $\theta$ per amb una alteració al paràmetre $\theta_i$. Les paraules \textit{generador} i \textit{discriminador} denoten els respectius models, per tant, \textit{Imatge\textsubscript{$i$}} i \textit{Predicció\textsubscript{$i$}} són els outputs del models.}
	\label{fig:alg_gen}
\end{figure}

El pseudocodi per aquest procediment es pot trobar en la figura \ref{fig:alg_gen}. En aquesta es pot veure que es crida al discriminador perquè posi etiquetes a les dues imatges generades, això es per poder avaluar aquestes etiquetes amb la funció de pèrdua, per després poder agafar la diferencia i d'aquesta manera calcular la derivada. El codi per el generador es pot trobar en l'apèndix, \ref{lst:gen_final}.

\section{Creació del model}

Quan ja es tenen les dues parts del model, aquestes s'han d'ajuntar d'alguna manera. El que jo he fet es posar-ho tot en una classe de Python anomenada \code{Quantum\_GAN}, que conté les funcions per definir el model, per executar-lo, per guardar les seves dades i per crear els gràfics que serveixen per avaluar l'eficiència del model. No fa falta entrar en detall sobre aquesta part en particular del codi. Només cal mencionar que és el tros de codi que junta tot, tant el discriminador i el generador, i les altres funcions que són necessàries, com per exemple la sigmoide. Aquestes funcions que no estan tant en l'arxiu del generador com el discriminador es troben en \code{functions.py}. 

Tanmateix s'han de tenir en compte algunes de les funcionalitats d'aquesta classe, com la creació de les gràfiques i com circulen les dades del generador al discriminadors. D'aquesta última qüestió parlaré a continuació.

A la funció de la classe \code{Quantum\_GAN} que s'utilitza per entrenar, \code{Quantum\_GAN.train()} se li dona, entre altres inputs, un dataset amb imatges reals i el soroll per poder entrenar el generador. Aquest dataset es divideix en grups d'imatges (els \textit{batchs}), cada \textit{batch} conté tant imatges reals, com soroll en la mateixa quantitat.

En una iteració primer s'optimitza el generador, que substitueix el soroll del \textit{batch} amb les imatges que genera. Llavors es passa el \textit{batch} al discriminador que s'optimitza tant amb les imatges reals com amb les imatges falses. Aquest és el procés per el qual s'optimitzen els dos models. No obstant, aquesta funció dona a terme altres coses que són necessàries per la creació dels gràfics, per exemple, selecciona una imatge real aleatòria i una de falsa per avaluar la funció de pèrdua en l'iteració, també crea les etiquetes utilitzades en aquesta l'avaluació. Totes aquestes dades s'utilitzen per la creació de diversos gràfics que mostren l'evolució d'aquestes dades a través de tota l'optimització.

\section{Execució del model}

No obstant en l'arxiu \code{qgan.py}, no es troba l'execució del model, només està la definició de la classe \code{Quantum\_GAN}. Això és perquè el codi realment s'executa en l'arxiu \code{main.py}\footnote{Veure apèndix \ref{lst:main}}. Aquest és l'únic arxiu que té codi que realment s'executa, els altres arxius només tenen definicions. Per projectes relativament grans, com aquest, convé tenir un arxiu que fa tot el treball, el qual crida a totes les funcions definides en altres arxius i les executa d'una manera ordenada. 

Com es pot veure en l'apèndix, \ref{lst:main}, aquesta arxiu té molt poc codi. En ell només es crea amb Numpy el dataset, es defineix el discriminador i el generador, amb els quals es crea el model amb \code{Quantum\_GAN}. Finalment es crida a la funció \code{Quantum\_GAN.train()} per optimitzar el model. Al acabar l'optimització es criden les funcions \code{Quantum\_GAN.plot()}, \code{Quantum\_GAN.create\_gif()} i \code{Quantum\_GAN.save()}, les quals donen a terme funcions complementàries com la creació de les gràfiques, la creació d'un GIF que mostra com les imatges vam evolucionant al llarg de l'optimització, i l'emmagatzematge de les dades rellevants que s'han creat durant l'optimització.  

Les imatges que vaig escollir per generar són les mateixes que van generar en l'article en el qual vaig basar el treball. No entraré molt en detall sobre les distribucions concretes que formen les imatges, però per tindre una imatge general sobre com són, es pot veure la figura. \todo{falta la figura}

Si executen el model, amb un mida de batch de $10$, tant el \textit{learning rate} del discriminador com del generador a $0.1$, i un total de iteracions de $400$, hi ha una garantia d'arribar a la convergència desitjada, es dir que, que els dos models arriben al equilibri de Nash i no poden continuar l'optimització. En aquest punt és quan les imatges falses i les reals són iguals.
\begin{figure}[H]
	\label{fig:labels_loss_400}
	\begin{subfigure}{0.45\textwidth}
		\includegraphics[width=\linewidth]{figures/model/loss_plot.png}
		\caption{}
		\label{fig:loss_400}
	\end{subfigure}
	\begin{subfigure}{0.45\textwidth}
		\includegraphics[width=\linewidth]{figures/model/labels_plot.png}
		\caption{} \label{fig:labels_400}
	\end{subfigure}
	\caption{En pot veure com per l'iteració 250, el model ja s'ha estabilitzat, ja que les etiquetes i el valor de la funció de pèrdua convergeixen en un valor. \textbf{A)} Funció de pèrdua per cada iteració. A partir de l'iteració 175, es pot veure com el valor de la funció s'estabilitza en l'interval $(-1.35, -1.4)$, això concorda amb els valors de les etiquetes en les mateixes iteracions, ja que $\log(\frac{1}{2}) + \log(1-\frac{1}{2}) \simeq -1.38$. \textbf{B)} Etiquetes per les imatges reals i generades per cada iteració. Es pot observar que els valors de les etiquetes per les imatges reals són més inestables que els valors de les generades. Això es perquè les imatges reals tenen una major variació en els valors dels píxels, mentre que en les generades aquest fet no es tan notable. Per tant el discriminador assigna etiquetes amb una major variació.}
\end{figure}

En la figura, \ref{fig:labels_400}, es pot veure com les etiquetes pels dos tipus d'imatges van oscil·lant fins a estabilitzar-se. El mateix es pot dir per la funció de pèrdua, com es pot veure en la figura \ref{fig:loss_400}.  

Degut a que aquests gràfics són molt semblants als seus anàlegs de les GANs clàssiques i que les distribucions reals i generades són pràcticament iguals, com es pot veure a la figura \ref{fig:comp_imatge}, considero que el model funciona correctament. 


\begin{figure}[H]
	\begin{subfigure}{0.51\textwidth}
		\includegraphics[width=\linewidth]{figures/model/real_distribution.png}
		\caption{Distribució d'una imatge real} \label{fig:1a}
	\end{subfigure}%
	\hspace*{\fill}   % maximize separation between the subfigures
	\begin{subfigure}{0.51\textwidth}
		\includegraphics[width=\linewidth]{figures/model/fake_distribution.png}
		\caption{Distribució d'una imatge generada} \label{fig:1b}
	\end{subfigure}%
	\hspace*{\fill}
	\caption{Comparació d'una imatge generada i una real, quan el model ha assolit la convergència. En el eix Y es pot veure el valor d'un píxel, mentre que en l'eix X estan els píxels. }
	\label{fig:comp_imatge} 
\end{figure}


Abans he especificat que al cap de $400$ iteracions podem tenir la garantir d'arribar al punt d'equilibri, no obstant, es pot arribar a aquest punt amb menys iteracions, el que vull dir es que amb $400$ de segur que s'arriva. Això és perquè, com a tots els model de \textit{machine learning} hi ha una part de sort implicada, si els paràmetres inicials són més semblants als paràmetres desitjats, el model assoli-ra la convergència més ràpidament. 
 
\chapter{Realització del experiment} 

Una vegada havia confirmat el correcte funcionament del model, vaig alterar el generador per poder acomodar els dos tipus de circuits quàntics que necessitava, uns amb un sistema ancilla, i uns altres sense.

Un sistema ancilla, són un grup de qubits sobre els quals es donen a terme operacions però que no es mesuren per treure el output del circuit. Aquests qubits es pot veure molt clar en la figura, \todo{poner figura}. 

\begin{figure}
	\begin{quantikz}
		\lstick[wires=2]{$\mathcal{A}$}& & \lstick{$\ket{0}$} &  \gate{R_y(\alpha_1)}& \gate{U_{\theta_{1, l}}} & \ctrl{1} & \qw & \qw & \qw & \gate{U_{\theta_{1, l-1}}} & \ctrl{1} & \qw & \qw & \qw & \qw  \\
		& & \lstick{$\ket{0}$} &  \gate{R_y(\alpha_2)} & \gate{U_{\theta_{2, l}}} & \control{} & \ctrl{1} & \qw & \qw & \gate{U_{\theta_{2, l-1}}} & \control{} & \ctrl{1} & \qw & \qw & \qw  \\
		&&\lstick{$\ket{0}$} &  \gate{R_y(\alpha_3)} & \gate{U_{\theta_{3, l}}} & \qw & \control{} & \ctrl{1} & \qw & \gate{U_{\theta_{3, l-1}}} & \qw & \control{} & \ctrl{1} & \qw &  \meter{} \\
		&&\lstick{$\ket{0}$} &  \gate{R_y(\alpha_4)} & \gate{U_{\theta_{4, l}}} & \qw & \qw & \control{} & \ctrl{1} & \gate{U_{\theta_{4, l-1}}} & \qw & \qw & \control{} & \ctrl{1} &  \meter{} \\
		&&\lstick{$\ket{0}$} &  \gate{R_y(\alpha_5)} & \gate{U_{\theta_{5, l}}} & \qw & \qw & \qw & \control{} & \gate{U_{\theta_{5, l-1}}} & \qw & \qw & \qw & \control{}  & \meter{}
	\end{quantikz}
	\caption{Aquí he marcat els qubits ancilla amb $\mathcal{A}$, són els dos primers. També al final del circuit he afegit mesures als qubits que s'han de mesurar.}
\end{figure}

Primer de tot he de mencionar que havia de fer alguns canvis al generador per acomodar aquests qubits ancilla. 

Segon, cal notar que no he seguit exactament els mateixos passos que en l'article original. En ell tenen aquesta equació \cite{QGAN_exp}: 
\begin{equation*}
\rho = \frac{\tr_A(\Pi_A \ket{\psi}\bra{\psi})}{\tr(\Pi_A\otimes I_{2^N-2^{N_A}}\ket{\psi}\bra{\psi})}
\end{equation*}

Com ja he comentat en la secció \ref{par_measurament}, no veig com aquesta equació pot tenir sentit, per tant la vaig ometre del meu experiment. 

L'alternativa que he fet servir són els mesuraments de Qiskit, al definir el circuit especifico quins són els qubits que no vull mesurar, que són els qubits que formen part del sistema ancilla. No obstant, no sé exactament que és lo que fa Qiskit amb el mesurament. Però si empro aquest procediment en altres circuits, dels quals n'en se el resultat, aquest mètode fa el que m'espero\footnote{Parlo del parells de Bell, els circuits quàntics amb entrellaçament més simples que es poden fer.}. 

L'arxiu que utilitzo per fer els experiments és \code{experiment.py}. En ell es pot veure com defineixo dos discriminadors\footnote{Que tenen les mateixes característiques.} i dos generadors, que es diferencien per els circuits que utilitzen, un amb qubits ancilla i l'altre sense. Aquests models s'agrupen en parelles per definir dues qGANs. 

Cal notar que els generadors i els discriminadors\footnote{Al principi pensava no tenir els mateixos paràmetres inicials pels discriminadors, però al veure les gràfiques de les etiquetes, l'efecte que tenen aquests és molt notable. Es pot veure com a vegades les etiquetes comencen en uns valors de $1$ i en altres de $0$. \href{https://drive.google.com/file/d/1kYZ1vmNYU17sofNluXFYnoATLfY5B0jG/view?usp=sharing}{link per veure una imatge amb totes les gràfiques} (perdó per l'informalitat)} comencen amb els mateixos paràmetres, per tant en exactament les mateixes condicions, menys els circuits quàntics es clar. També s'utilitza el mateix dataset i altres hiperparàmetres. 

\section{Anàlisi dels resultats}
Si comparem les gràfiques que mostren les etiquetes es pot veure una clara diferencia: Els models que tenen els circuits amb els qubits ancilla són més inestables que el que no els tenen. Això no vol dir necessàriament que siguin més eficients però l'estabilitat és un factor que es busca en les GANs. 

També es pot observar una clara diferencia en les imatges generades en la primera iteració. En les primeres imatges d'un generador amb la funció no-lienal es pot veure un píxel amb un valor de $1$ mentre que els altres estan al $0$. Mentre que en l'altre tipus de generador es pot veure que els píxels tenen més o menys el mateix valor, d'aquesta manera formant una distribució uniforme. Aquest fet probablement es causat per l'estructura del circuit que té els qubits ancilla. No obstant, perquè exactament passa això està fora dels meus coneixements sobre la matèria\footnote{Saber com es comporten sistemes quàntics que tenen parts entrellaçades com aquest està fora del meu àmbit.}. 

La part que realment m'intriga es que a partir de les primeres iteracions, en els circuits amb els qubits ancilla. El píxel que té el valor de $1$, passa d'un a un altre. Aquest comportament succeïx a absolutament totes les vegades que he executat el codi. Al igual que he dit abans, arribar a comprendre això està fora del meu nivell de coneixement. 

Estic bastant segur que aquesta fluctuació del píxels és el factor que causa l'inestabilitat que es pot observar en les etiquetes

Després de mirar les gràfiques que generaven els models, vaig posar-me a redactar les conclusions, no obstant, no estava satisfet amb la precisió de l'analisi de les dades. No podia saber amb certesa quin dels dos tipus de models era el més eficient. Necessitava una mètrica que en digues quina és la semblança entre les imatges generades i les imatges reals. Sabia que en l'article en el que he basat el treball els autors havien fet servir una mètrica anomenada \textit{Férchet Score} o puntuació de Férchet, en la qual s'empleava la distancia de Férchet. Aquesta distancia serveix per comparar dues distribucions a partir de la seva mitjana i la seva covariància. 

Llavors vaig decidir implantar aquesta mètrica, i veure com evoluciona al llarg de l'optimització. 

En un article sobre l'avalució de les imatges generades per les GAN \cite{sd_score}, vaig trobar aquesta equació per calcular la distancia de Férchet:
$$
FD(r, g) = \abs{\mu_r - \mu_g}^2 + \tr(\Sigma_r + \Sigma_g -2(\Sigma_r\Sigma_g)^{\frac{1}{2}})
$$

On $\mu$ és la mitjana\footnote{Jo he utilitzat la mitjana aritmètica.} i $\Sigma$ és la covariància d'una distribució. Aquesta equació l'he implementat en Python mitjançant matrius, es a dir les imatges. Només em feia falta trobar una funció per poder calcular la covariància d'una matriu, afortunadament Numpy en té una, on cada fila representa una variable d'una distribució. No puc estar 100\% segur de que he implementat aquesta mètrica correctament, degut a que no sé el funcionament exacte de la covariància, ni de la funció de Numpy. No obstant, sembla que funciona correctament. 

Cal notar que si les dues imatges són exactament iguals, la distancia dona pràcticament zero\footnote{Python diu que és d'un ordre de magnitud de $10^{-16}$ aproximadament.}. Per considerar que dues imatges són «acceptablement semblants», han de tenir una distancia entre elles de $10^{-3}$ aproximadament, i ha resultat molt útil.
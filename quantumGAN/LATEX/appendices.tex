\chapter{Més àlgebra lineal}
Ja he escrit bastants pàgines sobre àlgebra lineal, però aparentment no eren les suficients perquè estic content amb el treball\footnote{Hi han moltes coses guays i interessants que vull explicar.}, així que aquí hi ha més àlgebra lineal.


\section{Procediment de Gram–Schmidt}\label{gram}
El procediment de Gram-Schmidt és un mètode utilitzat per produir bases per a espais vectorials \cite{QCandQI:GramSchmidt}. Per un espai $V$ amb producte interior de $d$ dimensions amb el set de vectors ${\ket{v_1}, \cdots, \ket{v_d}}$, podem definir una nova base de vectors ortonormals $\{\ket{u}\}$. El primer element d'aquest set és $\ket{u_1} = \ket{v_1}/\norm{\ket{v_1}}$, amb el següent element $\ket{v_{k+1}}$ sent:
$$
\ket{u_{k+1}} = \frac{\ket{v_{k+1}} - \sum_{i=1}^{k} \bra{u_i}\ket{v_{k+1}}\ket{u_i}}{\norm{\ket{v_{k+1}} - \sum_{i=1}^{k} \bra{u_i}\ket{v_{k+1}}\ket{u_i}}}
$$
Per $k$ en el interval $1 \leq k \leq d-1$.

Si seguim per $k$ en $1 \leq k \leq d-1$, obtenim el set de vectors ${\ket{u_1}, \cdots , \ket{u_d}}$ que es una base vàlida per l'espai ortonormal per l'estai $V$. Els vectors creats han de tindre el mateix span\footnote{L'span d'un set de vectors són totes les combinacions lineals possibles amb aquests vectors.} que el dels vectors que originalment eren la base per $V$:
$$
\text{span}(\{\ket{v}\}) = \text{span}(\{\ket{v}\}) = V
$$
Cal notar que l'span de del set base és la definició del espai. En altres paraules, cada vector en $V$ pot ser representat per una combinació del vectors base. 

La prova de que és una base ortonormal és bastant simple:
Podem veure immediatament que els elements  de $\{ \ket{u} \}$ són vectors unitaris perquè estan normalitzats (els vectors $\ket{v_{k+1}} - \sum_{i=1}^{k} \bra{u_i}\ket{v_{k+1}}\ket{u_i}$ estan dividits per la seva norma). També podem veure que són ortogonals els uns als altres mirant que el producte interior entre els doni 0:

Per $k=1$:
$$
\ket{u_2} = \frac{\ket{v_2} - \bra{u_1}\ket{v_2}\ket{u_1}}{\norm{\ket{v_2} - \bra{u_1}\ket{v_2}\ket{u_1}}}
$$
Per tant el producte interior amb $\ket{v_1}$ és:
$$
\begin{aligned}
\bra{u_1}\ket{u_2} 
&= \bra{u_1} \left( \frac{\ket{v_2} - \bra{u_1}\ket{v_2}\ket{u_1}}{\norm{\ket{v_2} - \bra{u_1}\ket{v_2}\ket{u_1}}} \right) \\
&= \frac{\bra{u_1}\ket{v_2} - \bra{u_1}\ket{v_2}\bra{u_1}\ket{u_1}}{\norm{\ket{v_2} - \bra{u_1}\ket{v_2}\ket{u_1}}} \\
&= 0
\end{aligned}
$$
Per inducció podem veure que per $j \leq d$, amb $d$ sent la dimensió del espai vectorial:
$$
\begin{aligned}
	\bra{u_j}\ket{u_{n+1}} 
	& = \bra{u_j} \left( \frac{\ket{v_{n+1}} - \sum_{i=1}^{n} \bra{u_i}\ket{v_{n+1}}\ket{u_i}}{\norm{\ket{v_{n+1}} - \sum_{i=1}^{n} \bra{u_i}\ket{v_{n+1}}\ket{u_i}}} \right) \\
	& = \frac{\bra{u_j}\ket{v_{n+1}} - \sum_{i=1}^{n} \bra{u_i}\ket{v_{n+1}} \bra{u_j}\ket{u_i}}{\norm{\ket{v_{n+1}} - \sum_{i=1}^{n} \bra{u_i}\ket{v_{n+1}} \ket{u_i}}} \\
	& = \frac{\bra{u_j}\ket{v_{n+1}} - \sum_{i=1}^{n} \bra{u_i}\ket{v_{n+1}} \delta_{ij}}{\norm{\ket{v_{n+1}} - \sum_{i=1}^{n} \bra{u_i}\ket{v_{n+1}} \ket{u_i}}} \\
	& = \frac{\bra{u_j}\ket{v_{n+1}} - \bra{u_j}\ket{v_{n+1}}}{\norm{\ket{v_{n+1}} - \sum_{i=1}^{n} \bra{u_i}\ket{v_{n+1}} \ket{u_i}}} \\
	& = 0	\\
\end{aligned}
$$
Tot això no és veu molt clar al principi però cal recordar que el producte interior de dos vectors ortonormals és zero, i que el producte interior entre el mateix vector unitari és un.

\section{Curs ràpid de la notació de Dirac}
A la taula següent hi ha un resum de conceptes matemàtics de l'àlgebra lineal importants expressats en la notació de Dirac\footnote{La notació utilitzada per un espai vectorial complex i l'espai dels nombres complex no són de la notació de Dirac estàndard, però les poso per explicar el que signifiquen.} \cite{QCandQI:dirac_notation}

\begin{tabular}{ p{2cm}|p{12cm} }
	\hline
	Notació & Descripció\\
	\hline
	\hline
	$z$ & Nombre complex    \\
	$z^{*}$ & Conjugat complex d'un nombre complex $z$. $(a+ bi)^{*} = (a -bi)$\\
	$\ket{\psi} $ & Vector amb una etiqueta $\psi$. Conegut com \textit{ket}\\
	$\ket{\psi}^T$ & Transposada d'un vector $\ket{\psi}$ \\
	$\ket{\psi}^\dag $ &  Conjugat Hermitià d'un vector. $\ket{\psi}^\dag = (\ket{\psi}^T)^* $\\
	$\bra{\psi} $ & Vector dual a $\ket{\psi}$. $ \ket{\psi} = \bra{\psi}^{\dag}$ i $\bra{\psi} = \ket{\psi}^\dag$. Conegut com \textit{bra}\\
	$ \bra{\varphi}\ket{\psi} $ & Producte interior dels vectors $\bra{\varphi}$ i $\ket{\psi}$ \\
	$ \ket{\varphi}\bra{\psi} $ & Producte exterior del vectors $\bra{\varphi}$ i $\ket{\psi}$ \\
	$ \ket{\psi}\otimes\ket{\varphi}$ & Producte tensorial del vectors $\ket{\varphi}$ i $\ket{\psi}$ \\
	$ 0 $ & Vector zero i operador zero \\
	$ \mathbb{I}_n $ & Matriu identitat de dimensions $n\times n$ \\
	$ \mathbb{C}_n $ & Espai vectorial complex de dimensió $n$ \\
	$ \mathbb{C}_1$ o $\mathbb{C} $ & Espai del nombres complexos \\
	
\end{tabular}
\section{Més on la traça parcial}



\chapter{Computació Quàntica vs Mecànica Quàntica}
En la introducció havia mencionat que una de les raons per les quals havia començat a aprendre i recercar sobre computació quàntica era perquè era fàcil, en aquest apèndix explicaré exactament a que em refereixo per això amb un exemple pràctic. Dic que és fàcil, perquè si ho és, si es compara la computació quàntica amb la mecànica quàntica. Presentaré un exemple pràctic per il·lutrar-lo.  

En mecànica quàntica la manera més usual de representar els estats quàntics, com els orbitals d'un àtom d'hidrogen, és a través de \textit{wavefunctions} o funcions d'ona, no es solen representar mitjançant vectors d'estat. Aquestes funcions d'ona són molt útils i poden representar casos més generals que els vectors d'estat. No obstant, treballar amb elles és molt més complicat degut a que són funcions que depenen del temps, no son vectors. Això implica que s'han d'utilitzar altres operacions per normalitzar les funcions, determinar com evolucionen en el temps o per fer mesures. A continuació faré una comparació entre normalitzar una funció d'ona i un vectors d'estat.

\section{Normalitzar}
Degut a l'interpretació probabilística dels vectors d'estat i de les funcions d'ona, aquests objectes han de ser normalitzats perquè la suma de la probabilitats del possibles estats de mesura sigui $1$. 

Per una funció d'ona $\Psi(x,t)$ que representa una partícula, la probabilitat de trobar aquesta partícula en un punt $x$ és $\abs{\Psi(x,t)}^2$. Per tant, la funció d'ona ha de ser normalitza seguint la fórmula: 
\begin{equation}
\int_{-\infty}^{+\infty}\abs{\Psi(x,t)}^2\, dx\ = 1
\label{eq:norm_wave}
\end{equation}

Degut a que la funció d'ona evoluciona a través del temps d'acord amb l'equació de Schrödinger, veure la figura \ref{fig:schro}, qualsevol solució d'aquesta equació ha d'estar també normalitzada. En altres paraules, aquesta equació ha de preservar la normalització de les funcions d'ona \cite{IntroQM:normalizing}.
\begin{figure}
	$$
	i\hslash \pdv{\Psi}{t} = -\frac{\hslash^2}{2m}\pdv[2]{\Psi}{x}+V\Psi
	$$
	\caption{\textbf{Equació de Schrödinger}. On $\hslash$ és $h/2\pi$, i $V$ és una funció potencial d'energia.}
	\label{fig:schro}
\end{figure}

Podem provar que aquesta equació preserva la fórmula \ref{eq:norm_wave}, començant per la igualtat trivial:
$$
\dv{t} \int_{-\infty}^{+\infty}\abs{\Psi(x,t)}^2\, dx\ = \pdv{t} \int_{-\infty}^{+\infty}\abs{\Psi(x,t)}^2\, dx
$$
Per la regla del producte tenim que \footnote{A partir d'ara escriuré  $\Psi(x,t)$ simplement com $\Psi$ per no fer les equacions tan enrevessades.}:
$$
\pdv{t}\abs{\Psi}^2 = \pdv{t}(\Psi\Psi^*) = \Psi^*\pdv{\Psi}{t} + \pdv{\Psi^*}{t}\Psi
$$
Ara l'equació de Schrödinger diu que
$$
\pdv{\Psi}{t} = \frac{i\hslash}{2m}\pdv[2]{\Psi}{x} -  \frac{i}{\hslash}V\Psi
$$
després calculant el complex conjugat tenim que 
$$
\pdv{\Psi^*}{t} = - \frac{i\hslash}{2m}\pdv[2]{\Psi^*}{x} + \frac{i}{\hslash}V\Psi^*
$$
per tant
$$
\pdv{t}\abs{\Psi}^2 = \frac{i\hslash}{2m} \left( \Psi^*\pdv[2]{\Psi}{x} - \pdv[2]{\Psi^*}{x}\Psi \right) = \pdv{x} \left[ \frac{i\hslash}{2m} \left(\Psi^*\pdv{\Psi}{x} - \pdv{\Psi^*}{x}\Psi\right)\right]
$$
finalment podem avaluar l'integral del principi:
$$
\dv{t} \int_{-\infty}^{+\infty}\abs{\Psi(x,t)}^2\, dx\ = \frac{i\hslash}{2m} \left( \Psi^*\pdv{\Psi}{x} - \pdv{\Psi^*}{x}\Psi \right) \Big|_{-\infty}^{+\infty}
$$
Degut a que $\Psi(x,t)$ ha de convergir a zero quan $x$ va cap a infinit, es veritat que:
$$
\dv{t} \int_{-\infty}^{+\infty}\abs{\Psi(x,t)}^2\, dx\ = 0
$$
Es pot veure que l'integral es constant i per tant quan $\Psi$ es normalitzada a $t=0$, es queda d'aquesta manera per qualsevol $t$ (positiu es clar). 

\chapter{Polarització d'un fotó}
\label{appendix:optics}
En l'equació \ref{eq:photon_state} he excluit el concepte de fase, que determina el tipus de polarització que té un fotó. Hi han 3 tipus:
\begin{enumerate}
	\item \textbf{Linear:}
	Un fotó té polarització lineal quan els angles de la fase $\alpha_x$, $\alpha_y$ en els estats base $\ket{x},\ket{y}$ són iguals:
	\begin{align*}
		\ket{\nearrow} &= \cos(\theta) e^{i\alpha_x}\ket{x} + \cos(\theta)e^{i\alpha_y}\ket{y} \\
		&= [\cos(\theta)\ket{x} + \sin(\theta)\ket{y}]e^{i\alpha}
	\end{align*}
	On $\alpha=\alpha_x=\alpha_y$.
	\item \textbf{Circular:}
	Quan els angles $\alpha_x$, $\alpha_y$ son separats per exactament $\frac{\pi}{2}$ i la amplitud per les dos bases és la mateixa:
	\begin{align*}
		\ket{\nearrow} &= \frac{1}{\sqrt{2}}\cos(\theta)e^{i\alpha_x}\ket{x} \pm i\frac{1}{\sqrt{2}}\sin(\theta)e^{i\alpha_y}\ket{y} \\
					   &= [\cos(\theta)e^{i\alpha_x}\ket{x} \pm i\sin(\theta)e^{i\alpha_y}\ket{y}]\frac{1}{\sqrt{2}}
	\end{align*}
	On el signe $\pm$ indica la diferencia entre la diferencia entre la polarització circular cap a la dreta o la esquerra, amb $+$ i $-$, respectivament.
	\item \textbf{El·líptica:}
	On els angles $\alpha_x$, $\alpha_y$ son diferents per una quantitat arbitraria\footnote{Però que no sigui la quantitat que dona a terme la polarització circular.}:
	$$
	\ket{\nearrow} = \cos(\theta)e^{i\alpha_x}\ket{x} + \sin(\theta)e^{i\alpha_y}\ket{y}
	$$
	Aquest és el cas més general.
	
\end{enumerate}

\chapter{Complexitat i algoritmes quàntics}
\label{complexity}
En ciència de la computació existeix el concepte de \textit{Big-O Notation}, una forma d'expressar lo eficients que són els algoritmes per fer certes tasques, en altres paraules la complexitat dels algoritmes. Bàsicament es una forma de classificar-los segon la rapidesa que tenen en ver la tasca que els correspon, aquesta rapidesa no és mesura en segons, degut a que aquesta mètrica pot variar d'ordinador a ordinador per les diferencies en hardware que aquest poden tindre. En canvi es mesure en nombre d'operacions o temps directament, però sense unitats. 

La \textit{Big-O Notation} consisteixes en definir el temps màxim que necessita un algoritme, es denota com $O(\cdot)$ on l'argument usualment depèn de $n$ que és la mida del input al algoritme, per exemple un algoritme de cerca ha de cercar a través de $n$ coses. Com a un exemple més concret tenim que un l'algoritme de cerca de cadenes binaries corre en un temps $O(\log_{2} n)$, on $n$ és el nombre de cadenes entre les quals ha de cercar. Recorda que la notació $O(\cdot)$ és el màxim, es a dir es \textit{upper bounded}, això significa que $\log_{2} n$ és la quantitat de temps més gran en la que es troba la cadena, també es possible que es trobi-s'hi a la primera comprovació que es va\footnote{Que la primera cadena que es cerca, és la que s'ha de trobar.}, llavors l'algoritme acabaria en un temps $O(1)$. Simplement és una manera de mirar lo eficients que són els algoritmes en relació a la mida del input que tenen.

Amb aquesta notació tenim una manera de comparar la eficiència que tenen els algoritmes quàntics amb la del clàssics que tenen la mateixa funció. 

\section{Algoritme de Grover}
Al 1996, Lov Grover va presentar un algoritme quàntic per cercar en dades desordenades \cite{Grover_96} (e.g. cercar el número de telèfon d'una persona en una llista desordenada). Per aquest problema un algoritme clàssic té una complexitat de $O(N)$ cerques\footnote{Una cerca és quan es verifica si un element de la llista és l'element que es cerca.}, mentre que l'algoritme de Grover té una complexitat de $O(\sqrt{N})$, sent substancialment més eficient. En les paraules de Grover \cite{Grover_96} (adaptades), un ordinador clàssic per tindre un probabilitat de $\frac{1}{2}$ de trobar el número de telèfon d'una persona en una llista desordenada necessita mirar a un mínim de $\frac{N}{2}$ números, mentre que amb el seu s'obté el número de telèfon en només $O(\sqrt{N})$ passos\footnote{Per passos entenc que es refereix al nombre de vegades que es mira al oracle, es a dir el nombre que de vegades que es verifica si s'ha trobar el que es cerca.}.

L'algoritme funciona de la següent manera: 

\chapter{Codi}
En l'apèndix actual presentaré el codi que he utilitzat al llarg del treball. Està organitzat segons el moment en el qual he referenciat el codi en el text.

\section{Part I}
\subsection{Capítol 3}

\paragraph{Regressió lienal}
\label{lst:linear_regression}
Codi per efectuar una regressió lineal a dades que es generen al atzar en el mateix arxiu, l'utilitzo per poder generar una gràfic per il·lustrar un exemple de regressió lienal. Aquest troç de codi l'he tret de GitHub\footnote{Gist realitzat per l'usuari \textit{jimimvp}: \href{https://gist.github.com/jimimvp/05ece11fec25d5c8c009af9ba469d6c2}{link}}.

\begin{lstlisting}[language=Python, caption=Regressió lineal]
	import numpy as np
	from matplotlib import pyplot as plt
	import matplotlib
	
	font = {'family' : 'Helvetica',
		'size'   : 18}
	
	matplotlib.rc('font', **font)
	
	# generate the data
	np.random.seed(222)
	X = np.random.normal(0,1, (200, 1))
	w_target = np.random.normal(0,1, (1,1))
	# data + white noise
	y = X@w_target + np.random.normal(0, 1, (200,1))
	
	# least squares
	w_estimate = np.linalg.inv(X.T@X)@X.T@y
	y_estimate = X@w_estimate
	
	# plot the data
	plt.figure(figsize=(15,10))
	plt.scatter(X.flat, y_estimate.flat, label="Prediccio")
	plt.scatter(X.flat, y.flat, color='red', alpha=0.4, label="Dades")
	plt.tight_layout()
	plt.title("Regressio per diferencia de quadrats")
	plt.legend()
	plt.savefig("least_squares.png")
	plt.show()
\end{lstlisting}

\section{Part II}
\subsection{Capítol 6}

\paragraph{Codi original per la xarxa neuronal clàssica}
\label{lst:disc_original}
Està extret del \href{https://github.com/mnielsen/neural-networks-and-deep-learning}{repositori de GitHub de Micheal Nielsen}, concretament del arxiu \code{network.py}.


\begin{lstlisting}[language=Python, caption=Codi original per la xarxa neuronal clàssica]
"""
network.py
~~~~~~~~~~
A module to implement the stochastic gradient descent learning
algorithm for a feedforward neural network.  Gradients are calculated
using backpropagation.  Note that I have focused on making the code
simple, easily readable, and easily modifiable.  It is not optimized,
and omits many desirable features.
"""

#### Libraries
# Standard library
import random

# Third-party libraries
import numpy as np

class Network(object):

	def __init__(self, sizes):
		"""The list ``sizes`` contains the number of neurons in the
		respective layers of the network.  For example, if the list
		was [2, 3, 1] then it would be a three-layer network, with the
		first layer containing 2 neurons, the second layer 3 neurons,
		and the third layer 1 neuron.  The biases and weights for the
		network are initialized randomly, using a Gaussian
		distribution with mean 0, and variance 1.  Note that the first
		layer is assumed to be an input layer, and by convention we
		won't set any biases for those neurons, since biases are only
		ever used in computing the outputs from later layers."""
		self.num_layers = len(sizes)
		self.sizes = sizes
		self.biases = [np.random.randn(y, 1) for y in sizes[1:]]
		self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]

	def feedforward(self, a):
		"""Return the output of the network if ``a`` is input."""
		for b, w in zip(self.biases, self.weights):
			a = sigmoid(np.dot(w, a)+b)
		return a

	def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None):
		"""Train the neural network using mini-batch stochastic
		gradient descent.  The ``training_data`` is a list of tuples
		``(x, y)`` representing the training inputs and the desired
		outputs.  The other non-optional parameters are
		self-explanatory.  If ``test_data`` is provided then the
		network will be evaluated against the test data after each
		epoch, and partial progress printed out.  This is useful for
		tracking progress, but slows things down substantially."""
		if test_data: n_test = len(test_data)
		n = len(training_data)
		for j in xrange(epochs):
			random.shuffle(training_data)
			mini_batches = [training_data[k:k+mini_batch_size] for k in xrange(0, n, mini_batch_size)]
			for mini_batch in mini_batches:
				self.update_mini_batch(mini_batch, eta)
			if test_data:
				print "Epoch {0}: {1} / {2}".format(j, self.evaluate(test_data), n_test)
			else:
				print "Epoch {0} complete".format(j)

	def update_mini_batch(self, mini_batch, eta):
		"""Update the network's weights and biases by applying
		gradient descent using backpropagation to a single mini batch.
		The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``
		is the learning rate."""
		nabla_b = [np.zeros(b.shape) for b in self.biases]
		nabla_w = [np.zeros(w.shape) for w in self.weights]
		for x, y in mini_batch:
			delta_nabla_b, delta_nabla_w = self.backprop(x, y)
			nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]
			nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]
		self.weights = [w-(eta/len(mini_batch))*nw for w, nw in zip(self.weights, nabla_w)]
		self.biases = [b-(eta/len(mini_batch))*nb for b, nb in zip(self.biases, nabla_b)]

	def backprop(self, x, y):
		"""Return a tuple ``(nabla_b, nabla_w)`` representing the
		gradient for the cost function C_x.  ``nabla_b`` and
		``nabla_w`` are layer-by-layer lists of numpy arrays, similar
		to ``self.biases`` and ``self.weights``."""
		
		nabla_b = [np.zeros(b.shape) for b in self.biases]
		nabla_w = [np.zeros(w.shape) for w in self.weights]
		# feedforward
		activation = x
		activations = [x] # list to store all the activations, layer by layer
		zs = [] # list to store all the z vectors, layer by layer
		for b, w in zip(self.biases, self.weights):
			z = np.dot(w, activation)+b
			zs.append(z)
			activation = sigmoid(z)
			activations.append(activation)
			
		# backward pass
		delta = self.cost_derivative(activations[-1], y) * sigmoid_prime(zs[-1])
		nabla_b[-1] = delta
		nabla_w[-1] = np.dot(delta, activations[-2].transpose())
		# Note that the variable l in the loop below is used a little
		# differently to the notation in Chapter 2 of the book.  Here,
		# l = 1 means the last layer of neurons, l = 2 is the
		# second-last layer, and so on.  It's a renumbering of the
		# scheme in the book, used here to take advantage of the fact
		# that Python can use negative indices in lists.
		for l in xrange(2, self.num_layers):
			z = zs[-l]
			sp = sigmoid_prime(z)
			delta = np.dot(self.weights[-l+1].transpose(), delta) * sp
			nabla_b[-l] = delta
			nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())
		return (nabla_b, nabla_w)

	def evaluate(self, test_data):
		"""Return the number of test inputs for which the neural
		network outputs the correct result. Note that the neural
		network's output is assumed to be the index of whichever
		neuron in the final layer has the highest activation."""
		test_results = [(np.argmax(self.feedforward(x)), y) for (x, y) in test_data]
		return sum(int(x == y) for (x, y) in test_results)

	def cost_derivative(self, output_activations, y):
		"""Return the vector of partial derivatives \partial C_x /
		\partial a for the output activations."""
		return (output_activations-y)

#### Miscellaneous functions
def sigmoid(z):
	"""The sigmoid function."""
	return 1.0/(1.0+np.exp(-z))

def sigmoid_prime(z):
	"""Derivative of the sigmoid function."""
	return sigmoid(z)*(1-sigmoid(z))
\end{lstlisting}

\paragraph{Codi final per el discriminador}
\label{lst:disc_final}
Aquest codi es pot trobar al \href{https://github.com/tomiock/qGAN}{repositori del treball} en l'arxiu \code{discriminator\_functional.py}. 

\begin{lstlisting}[language=Python, caption=Codi final pel discriminador]
"""DISCRIMINATOR"""
import json
from typing import Dict, List

import numpy as np

from quantumGAN.functions import BCE_derivative, minimax_derivative_fake, minimax_derivative_real, sigmoid, sigmoid_prime


def load(filename):
	f = open(filename, "r")
	data = json.load(f)
	f.close()
	# cost = getattr(sys.modules[__name__], data["cost"])
	net = ClassicalDiscriminator_that_works(data["sizes"], data["loss"])
	net.weights = [np.array(w) for w in data["weights"]]
	net.biases = [np.array(b) for b in data["biases"]]
	return net


class ClassicalDiscriminator_that_works:

	def __init__(	self,
					sizes: List[int],
					type_loss: str) -> None:

		self.num_layers = len(sizes)
		self.sizes = sizes
		self.type_loss = type_loss
		self.data_loss = {"real": [], "fake": []}
		self.ret: Dict[str, any] = {"loss": [],
			"label real": [],
			"label fake": [],
			"label fake time": [],
			"label real time": []}
		self.biases = [np.random.randn(y, ) for y in sizes[1:]]
		self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]

	def feedforward(self, a):
		"""Return the output of the network if ``a`` is input."""
		for b, w in zip(self.biases, self.weights):
a = sigmoid(np.dot(w, a) + b)
return a

def predict(self, x):
# feedforward
activation = x
zs = []  # list to store all the z vectors, layer by layer
for b, w in zip(self.biases, self.weights):
z = np.dot(w, activation) + b
zs.append(z)
activation = sigmoid(z)
return activation

def evaluate(self, test_data):

test_results = [(np.argmax(self.feedforward(x)), y)
for (x, y) in test_data]
return sum(int(x == y) for (x, y) in test_results)


def forwardprop(self, x: np.ndarray):
activation = x
activations = [x]  # list to store all the activations, layer by layer
zs = []  # list to store all the z vectors, layer by layer
for b, w in zip(self.biases, self.weights):
z = np.dot(w, activation) + b
zs.append(z)
activation = sigmoid(z)
activations.append(activation)
return activation, activations, zs

def backprop_bce(self, image, label):
"""Return a tuple ``(nabla_b, nabla_w)`` representing the
gradient for the cost function C_x.  ``nabla_b`` and
``nabla_w`` are layer-by-layer lists of numpy arrays, similar
to ``self.biases`` and ``self.weights``."""
nabla_b = [np.zeros(b.shape) for b in self.biases]
nabla_w = [np.zeros(w.shape) for w in self.weights]

# feedforward and back error calculation depending on type of image
activation, activations, zs = self.forwardprop(image)
delta = BCE_derivative(activations[-1], label) * sigmoid_prime(zs[-1])

# backward pass
nabla_b[-1] = delta
nabla_w[-1] = np.dot(delta, activations[-2].reshape(1, activations[-2].shape[0]))

for l in range(2, self.num_layers):
z = zs[-l]
delta = np.dot(self.weights[-l + 1].transpose(), delta) * sigmoid_prime(z)
nabla_b[-l] = delta
nabla_w[-l] = np.dot(delta.reshape(delta.shape[0], 1), activations[-l - 1].reshape(1, activations[-l - 1].shape[0]))
return nabla_b, nabla_w, activations[-1]

def backprop_minimax(self, real_image, fake_image, is_real):
"""Return a tuple ``(nabla_b, nabla_w)`` representing the
gradient for the cost function C_x.  ``nabla_b`` and
``nabla_w`` are layer-by-layer lists of numpy arrays, similar
to ``self.biases`` and ``self.weights``."""
nabla_b = [np.zeros(b.shape) for b in self.biases]
nabla_w = [np.zeros(w.shape) for w in self.weights]

# feedforward and back error calculation depending on type of image
activation_real, activations_real, zs_real = self.forwardprop(real_image)
activation_fake, activations_fake, zs_fake = self.forwardprop(fake_image)

if is_real:
delta = minimax_derivative_real(activations_real[-1]) * sigmoid_prime(zs_real[-1])
activations, zs = activations_real, zs_real
else:
delta = minimax_derivative_fake(activations_fake[-1]) * sigmoid_prime(zs_fake[-1])
activations, zs = activations_fake, zs_fake

# backward pass
nabla_b[-1] = delta
nabla_w[-1] = np.dot(delta, activations[-2].reshape(1, activations[-2].shape[0]))

for l in range(2, self.num_layers):
z = zs[-l]
delta = np.dot(self.weights[-l + 1].transpose(), delta) * sigmoid_prime(z)
nabla_b[-l] = delta
nabla_w[-l] = np.dot(delta.reshape(delta.shape[0], 1),
activations[-l - 1].reshape(1, activations[-l - 1].shape[0]))
return nabla_b, nabla_w, activations[-1]

def train_mini_batch(self, mini_batch, learning_rate):
global label_real, label_fake
nabla_b = [np.zeros(b.shape) for b in self.biases]
nabla_w = [np.zeros(w.shape) for w in self.weights]

if self.type_loss == "binary cross entropy":
for real_image, fake_image in mini_batch:
delta_nabla_b, delta_nabla_w, label_real = self.backprop_bce(real_image, np.array([1.]))
nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]
nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]

delta_nabla_b, delta_nabla_w, label_fake = self.backprop_bce(fake_image, np.array([0.]))
nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]
nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]

elif self.type_loss == "minimax":
for real_image, fake_image in mini_batch:
delta_nabla_b, delta_nabla_w, label_real = self.backprop_minimax(real_image, fake_image, True)
nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]
nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]

delta_nabla_b, delta_nabla_w, label_fake = self.backprop_minimax(real_image, fake_image, False)
nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]
nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]
else:
raise Exception("type of loss function not valid")

# gradient descent
# nabla_w and nabla_b are multiplied by the learning rate
# and taken the mean of (dividing by the mini batch size)
self.weights = [w - (learning_rate / len(mini_batch)) * nw
for w, nw in zip(self.weights, nabla_w)]
self.biases = [b - (learning_rate / len(mini_batch)) * nb
for b, nb in zip(self.biases, nabla_b)]
\end{lstlisting}

